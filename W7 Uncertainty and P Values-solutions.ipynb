{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6592e29f-e1ab-41ea-a9f3-11a855bdb02b",
   "metadata": {},
   "source": [
    "# W7: Uncertainty and P-Values - Solutions\n",
    "\n",
    "This week we are going to focus on interpreting standard errors, t-statistics, and p-values. By the end of this notebook, you should have a better understanding of what p-values mean and do not mean. \n",
    "\n",
    "We will be using data wherein students were randomly assigned to tutoring. The dataset has two main variables: \n",
    "- **`Mentored`**: `TRUE` if the student participated in tutoring, `FALSE` if the student did not participate in tutoring\n",
    "- **`Final`**: Each student's final score in the course "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec162e3-845c-4873-897e-f883bff45bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin by loading the estimatr package and the dataset \n",
    "library(estimatr) \n",
    "data <- read.csv(\"final_scores.csv\")\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36153251-0e1d-4eaa-a18e-ca5c8ee5bdda",
   "metadata": {},
   "source": [
    "To explain the relationship between the standard deviation and the standard error, I will first show you what a sampling distribution is. In the code chunks below, calculate the mean and standard deviation of the final scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7df5f-4c45-4d42-87c1-45afe36fdeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.score <- mean(data$Final) #replace NULL with your code \n",
    "mean.score \n",
    "\n",
    "sd.score <- sd(data$Final) #replace NULL with your code \n",
    "sd.score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c94ee5-7738-4276-b14b-b834d8338ec8",
   "metadata": {},
   "source": [
    "The standard deviation tells us the spread of the final scores in the class whereas the mean tells us the average score in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30657a08-dddd-4aa4-b4c6-3612c08c0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you do not have to understand the code below; run the cells and I will explain the output \n",
    "library(tidyverse)\n",
    "set.seed(94608) #makes sure results are same across all laptops\n",
    "mean.function <- function(x){\n",
    "    sample <- sample_n(x, 100, replace = TRUE)\n",
    "    mean.sample <- mean(sample$Final)\n",
    "    return(mean.sample)\n",
    "}\n",
    "sample.means <- replicate(1000, mean.function(data))\n",
    "\n",
    "hist(sample.means, \n",
    "    main = \"Sampling Distribution of Sample Means\",\n",
    "    xlab = \"Sample Mean\",\n",
    "    ylab = \"Frequency\")\n",
    "abline(v = mean(sample.means), col = \"red\")\n",
    "\n",
    "std.error <- sd(sample.means)\n",
    "std.error\n",
    "\n",
    "mean.sampling.dist <- mean(sample.means) \n",
    "mean.sampling.dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c02e95-4289-4af4-9d28-ea25bd716a0a",
   "metadata": {},
   "source": [
    "What I did here is: \n",
    "- I created a function that takes a sample of size 100 from the final scores of students and calculates the mean of each sample\n",
    "- I then repeated the process 1000 times and stored the results in `sample.means` (1000 sample means)\n",
    "- I plotted the distribution of those sample means - this is called a sampling distribution\n",
    "- I then took the standard error of that sampling distribution\n",
    "\n",
    "Compare the mean of the sampling distribution to the mean in our data. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b0a4b7-6386-411c-a36d-24bb55330e89",
   "metadata": {},
   "source": [
    "## Standard Error\n",
    "\n",
    "What is the standard error of the sample below? Let's find the standard error using a sample of final scores we take below (`our.sample$Final`).\n",
    "\n",
    "$$Standard Error = \\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1f174-8d5d-469b-86e7-9e7ca7b193b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(94608)\n",
    "\n",
    "our.sample <- sample_n(data, 100, replace = TRUE) \n",
    "\n",
    "#calculate the following using the sd() and length() functions\n",
    "s1 <- sd(our.sample$Final[our.sample$Mentored == TRUE]) #standard dev for tutored\n",
    "s1\n",
    "s2 <- sd(our.sample$Final[our.sample$Mentored == FALSE]) #standard dev for not tutored\n",
    "s2\n",
    "n1 <- length(our.sample$Final[our.sample$Mentored == TRUE]) #sample size of tutored, using the length function\n",
    "n1\n",
    "n2 <- length(our.sample$Final[our.sample$Mentored == FALSE]) #sample size of not tutored, using the length function\n",
    "n2\n",
    "\n",
    "#mathematically calculate using the formula above \n",
    "#hint: use sqrt() to calculate the square root \n",
    "se <- sqrt((s1^2/n1) + \n",
    "               (s2^2/n2)) \n",
    "se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5735dfe8-6c16-43f0-8dd3-1eba3a0f3b30",
   "metadata": {},
   "source": [
    "## Statistical Significance\n",
    "\n",
    "Let's say we want to know whether assignment to tutoring improved students' final scores in the course. \n",
    "\n",
    "What is our null hypothesis? What is our alternative hypothesis? \n",
    "\n",
    "- **Null hypothesis:** There is no difference in the final scores of the students who were tutored and not tutored.\n",
    "- **Alternative hypothesis:** There is a difference in the final scores of students who were tutored and not tutored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817bd076-9fe5-4267-9566-437f5d7d6fa7",
   "metadata": {},
   "source": [
    "First, manually calculate the difference in means, the standard error (using the formula above), and the t-statistic for the final scores between students who were and were not tutored in the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b1efe-c874-4b4c-9354-fadef2a5757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.in.means <- mean(data$Final[data$Mentored == TRUE]) - mean(data$Final[data$Mentored == FALSE])\n",
    "se.dim <- sqrt((sd(data$Final[data$Mentored == TRUE])^2/length(data$Final[data$Mentored == TRUE])) + \n",
    "               (sd(data$Final[data$Mentored == FALSE])^2/length(data$Final[data$Mentored == FALSE])))\n",
    "t.stat <- diff.in.means/se.dim\n",
    "\n",
    "diff.in.means\n",
    "se.dim\n",
    "t.stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00289180-18e1-4032-bcb6-a196db5c686d",
   "metadata": {},
   "source": [
    "Now, using the `difference_in_means()` function, check your calculations. You should get the same difference in means (estimate), standard error, and t-statistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a43bd2-521e-4a0a-91bb-ce2f6a9fa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_in_means(Final ~ Mentored, data, condition1 = FALSE, condition2 = TRUE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f20a6b2-8abd-460c-a86d-e72c10382b50",
   "metadata": {},
   "source": [
    "We observe a p-value of nearly 0. What does this mean? \n",
    "- It means, if the null hypothesis were true, there is a nearly 0 percent chance of observing a difference in means as extreme or more extreme than the one we observed.\n",
    "\n",
    "Can you think of another way to confirm your results? (**Hint**: Think about the t-statistic)\n",
    "- We can confirm these results by looking at the t-statistic, which is much larger than 1.96. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
